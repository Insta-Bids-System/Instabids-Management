name: Auto-rebase PRs and autofix trivial conflicts

on:
  push:
    branches: [ main ]                 # run when main moves
  pull_request:                        # run when PRs open/update/reopen
    types: [opened, synchronize, reopened]
  schedule:
    - cron: "*/20 * * * *"             # keep PRs fresh
  issue_comment:
    types: [created]                   # comment /autofix on a PR to run it
  workflow_dispatch: {}                # manual run from Actions tab

permissions:
  contents: write
  pull-requests: write
  issues: write

env:
  CODEX_HANDLE: "@codex"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  collect:
    if: github.event_name != 'issue_comment'
    runs-on: ubuntu-latest
    outputs:
      prs: ${{ steps.out.outputs.prs }}
    steps:
      - id: out
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          script: |
            const owner = context.repo.owner;
            const repo  = context.repo.repo;
            const all = await github.paginate(
              github.rest.pulls.list, { owner, repo, state: 'open', per_page: 100 }
            );
            // Only PRs whose head branch is in THIS repo (token can push there)
            const target = all
              .filter(pr => pr.base.ref === 'main' && pr.head.repo.full_name === `${owner}/${repo}`)
              .map(pr => ({ number: pr.number, ref: pr.head.ref, repo: pr.head.repo.full_name }));
            core.setOutput('prs', JSON.stringify(target));

  update:
    if: github.event_name != 'issue_comment' && fromJSON(needs.collect.outputs.prs).length > 0
    needs: collect
    runs-on: ubuntu-latest
    strategy:
      matrix:
        pr: ${{ fromJSON(needs.collect.outputs.prs) }}
      max-parallel: 3
    steps:
      - name: Checkout PR head branch
        uses: actions/checkout@v4
        with:
          repository: ${{ matrix.pr.repo }}
          ref: ${{ matrix.pr.ref }}
          fetch-depth: 0
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}

      - name: Bot identity & rerere
        run: |
          git config user.name  "autorebase-bot"
          git config user.email "autorebase-bot@users.noreply.github.com"
          git config rerere.enabled true
          git remote add upstream "https://github.com/${{ github.repository }}.git"
          git fetch upstream main

      - name: Rebase onto latest main (continue on conflicts)
        run: git rebase upstream/main || true

      - name: Autofix common conflicts (md/lockfiles + python imports/routers)
        run: |
          python - <<'PY'
          import re, subprocess, pathlib
          sh=lambda c: subprocess.run(c, shell=True, check=False)
          # Markdown: union (drop markers)
          for p in pathlib.Path('.').rglob('*.md'):
              t=p.read_text(errors='ignore')
              if '<<<<<<<' in t and '>>>>>>>' in t:
                  t=re.sub(r'^<<<<<<< .*?\n|^=======\n|^>>>>>>> .*?\n','',t,flags=re.M)
                  p.write_text(t); sh(f"git add {p}")
          # Lockfiles: prefer ours
          for n in ['package-lock.json','yarn.lock','pnpm-lock.yaml','poetry.lock']:
              p=pathlib.Path(n)
              if p.exists(): sh(f"git checkout --ours {n} && git add {n}")
          # Python: union/dedupe imports, dedupe include_router blocks
          CON=re.compile(r"<<<<<<< .*?\n(.*?)\n=======\n(.*?)\n>>>>>>> .*?\n", re.S)
          def dedupe(xs):
              out=[]; seen=set()
              for x in xs:
                  if x not in seen:
                      out.append(x); seen.add(x)
              return out
          def merge(a,b):
              A=[l.rstrip() for l in a.strip().splitlines()]
              B=[l.rstrip() for l in b.strip().splitlines()]
              if ''.join(A)==''.join(B):
                  return '\n'.join(A)+'\n'
              if all(l.startswith(('import ','from ')) or l=='' for l in A+B):
                  imp=dedupe([*A,*B]); imp=[l for l in imp if l]; imp.sort()
                  return '\n'.join(imp)+'\n'
              if 'app.include_router' in '\n'.join([*A,*B]):
                  def blocks(L):
                      buf=[]; out=[]
                      for l in L+['']:
                          buf.append(l)
                          if l.strip().startswith(')') or l.strip()=='':
                              ch='\n'.join(buf).strip()
                              if 'app.include_router' in ch: out.append(ch)
                              buf=[]
                      return out
                  m=dedupe(blocks(A)+blocks(B))
                  if m: return '\n\n'.join(m)+'\n'
              if len(A)<=10 and len(B)<=10:
                  return '\n'.join(dedupe(A+B))+'\n'
              return None
          for p in pathlib.Path('.').rglob('*.py'):
              t=p.read_text(errors='ignore')
              if '<<<<<<<' in t and '>>>>>>>' in t:
                  def repl(m):
                      r=merge(m.group(1), m.group(2))
                      return m.group(0) if r is None else r
                  new=CON.sub(repl,t)
                  if new!=t:
                      p.write_text(new); sh(f"git add {p}")
          PY

      - name: Continue rebase if possible
        run: git -c core.editor=true rebase --continue || true

      - name: Check remaining conflicts
        id: conf
        run: |
          git ls-files -u | cut -f2 | sort -u > /tmp/conflicts || true
          cat /tmp/conflicts || true
          echo "count=$(wc -l < /tmp/conflicts | tr -d ' ')" >> $GITHUB_OUTPUT

      - name: Format (normalize diffs)
        if: steps.conf.outputs.count == '0'
        run: |
          python -m pip install --upgrade pip >/dev/null 2>&1 || true
          pip install black isort >/dev/null 2>&1 || true
          isort . || true
          black . || true
          git add -A

      - name: Commit & push if clean
        if: steps.conf.outputs.count == '0'
        run: |
          if ! git diff --cached --quiet; then
            git commit -m "auto-rebase on main (+safe conflict resolves)"
          fi
          git push --force-with-lease origin HEAD:${{ matrix.pr.ref }}

      - name: Post conflicts per file for Codex
        if: steps.conf.outputs.count != '0'
        run: |
          python - <<'PY'
          import re, json, pathlib, os, textwrap, math, sys
          import subprocess as sp

          def sh(c):
              return sp.run(c, shell=True, capture_output=True, text=True, check=False)

          # Find conflicted files (stages 1/2/3 present)
          out = sh("git ls-files -u | cut -f2 | sort -u")
          files = [f for f in out.stdout.splitlines() if f]

          CON = re.compile(r"<<<<<<< [^\n]+\n(.*?)\n=======\n(.*?)\n>>>>>>> [^\n]+\n", re.S)

          # Build per-file markdown with OURS/THEIRS blocks
          payloads = []
          MAX = 28000  # keep well under GH comment body limit (~65k). We'll split big files.
          for path in files:
              p = pathlib.Path(path)
              try:
                  t = p.read_text(errors="ignore")
              except Exception:
                  continue
              blocks = []
              for i,m in enumerate(CON.finditer(t), start=1):
                  ours = m.group(1).rstrip()
                  theirs = m.group(2).rstrip()
                  chunk = f"**{path} â€” conflict {i}**\n\n" \
                          f"```diff\n<<<<<<< OURS\n{ours}\n=======\n{theirs}\n>>>>>>> THEIRS\n```\n"
                  blocks.append(chunk)
              if not blocks:
                  continue
              body = f"@{os.environ.get('CODEX_HANDLE','codex').lstrip('@')} please resolve the conflicts in `{path}`.\n" \
                     f"Return **GitHub Suggested changes** if possible; otherwise reply with a full file replacement in a fenced block like:\n\n" \
                     f"```resolved:{path}\n<entire corrected file contents>\n```\n\n" \
                     + "\n".join(blocks)

              # split large comments
              if len(body) <= MAX:
                  payloads.append(body)
              else:
                  parts = math.ceil(len(body)/MAX)
                  for i in range(parts):
                      payloads.append(f"(part {i+1}/{parts})\n\n" + body[i*MAX:(i+1)*MAX])

          # Post each payload as an issue comment
          if payloads:
              # use gh api (already installed on hosted runners)
              for body in payloads:
                  body = body.replace('"','\\"').replace("$","\\$")  # escape shell
                  cmd = f'gh api repos/${{GITHUB_REPOSITORY}}/issues/${{matrix.pr.number}}/comments -f body="{body}"'
                  sh(cmd)
          PY
        env:
          GH_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          CODEX_HANDLE: ${{ env.CODEX_HANDLE }}

  one-pr:
    if: github.event_name == 'issue_comment' &&
        github.event.issue.pull_request != null &&
        contains(github.event.comment.body, '/autofix')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with: 
          fetch-depth: 0
          token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}

      - name: Get PR info
        id: pr
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          script: |
            const { data: pr } = await github.rest.pulls.get({
              owner: context.repo.owner, repo: context.repo.repo,
              pull_number: context.payload.issue.number
            });
            core.setOutput('number', pr.number);
            core.setOutput('ref', pr.head.ref);

      - name: Configure bot & fetch
        run: |
          git config user.name  "autorebase-bot"
          git config user.email "autorebase-bot@users.noreply.github.com"
          git config rerere.enabled true
          git fetch origin "${{ steps.pr.outputs.ref }}"
          git checkout "${{ steps.pr.outputs.ref }}"
          git fetch origin main

      - name: Rebase
        run: git rebase origin/main || true

      - name: Autofix common conflicts (same logic)
        run: |
          python - <<'PY'
          import re, subprocess, pathlib
          sh=lambda c: subprocess.run(c, shell=True, check=False)
          for p in pathlib.Path('.').rglob('*.md'):
              t=p.read_text(errors='ignore')
              if '<<<<<<<' in t and '>>>>>>>' in t:
                  t=re.sub(r'^<<<<<<< .*?\n|^=======\n|^>>>>>>> .*?\n','',t,flags=re.M)
                  p.write_text(t); sh(f"git add {p}")
          for n in ['package-lock.json','yarn.lock','pnpm-lock.yaml','poetry.lock']:
              p=pathlib.Path(n)
              if p.exists(): sh(f"git checkout --ours {n} && git add {n}")
          CON=re.compile(r"<<<<<<< .*?\n(.*?)\n=======\n(.*?)\n>>>>>>> .*?\n", re.S)
          def dedupe(xs):
              out=[]; seen=set()
              for x in xs:
                  if x not in seen:
                      out.append(x); seen.add(x)
              return out
          def merge(a,b):
              A=[l.rstrip() for l in a.strip().splitlines()]
              B=[l.rstrip() for l in b.strip().splitlines()]
              if ''.join(A)==''.join(B):
                  return '\n'.join(A)+'\n'
              if all(l.startswith(('import ','from ')) or l=='' for l in A+B):
                  imp=dedupe([*A,*B]); imp=[l for l in imp if l]; imp.sort()
                  return '\n'.join(imp)+'\n'
              if 'app.include_router' in '\n'.join([*A,*B]):
                  def blocks(L):
                      buf=[]; out=[]
                      for l in L+['']:
                          buf.append(l)
                          if l.strip().startswith(')') or l.strip()=='':
                              ch='\n'.join(buf).strip()
                              if 'app.include_router' in ch: out.append(ch)
                              buf=[]
                      return out
                  m=dedupe(blocks(A)+blocks(B))
                  if m: return '\n\n'.join(m)+'\n'
              if len(A)<=10 and len(B)<=10:
                  return '\n'.join(dedupe(A+B))+'\n'
              return None
          for p in pathlib.Path('.').rglob('*.py'):
              t=p.read_text(errors='ignore')
              if '<<<<<<<' in t and '>>>>>>>' in t:
                  def repl(m):
                      r=merge(m.group(1), m.group(2))
                      return m.group(0) if r is None else r
                  new=CON.sub(repl,t)
                  if new!=t:
                      p.write_text(new); sh(f"git add {p}")
          PY

      - name: Continue rebase if possible
        run: git -c core.editor=true rebase --continue || true

      - name: Check remaining conflicts
        id: conf
        run: |
          git ls-files -u | cut -f2 | sort -u > /tmp/conflicts || true
          cat /tmp/conflicts || true
          echo "count=$(wc -l < /tmp/conflicts | tr -d ' ')" >> $GITHUB_OUTPUT

      - name: Format (normalize diffs)
        if: steps.conf.outputs.count == '0'
        run: |
          python -m pip install --upgrade pip >/dev/null 2>&1 || true
          pip install black isort >/dev/null 2>&1 || true
          isort . || true
          black . || true
          git add -A

      - name: Commit & push if clean
        if: steps.conf.outputs.count == '0'
        run: |
          if ! git diff --cached --quiet; then
            git commit -m "autofix: rebase + safe conflict resolves"
          fi
          git push --force-with-lease origin HEAD:${{ steps.pr.outputs.ref }}

      - name: Post conflicts per file for Codex (manual path)
        if: steps.conf.outputs.count != '0'
        run: |
          python - <<'PY'
          import re, json, pathlib, os, textwrap, math, sys
          import subprocess as sp

          def sh(c):
              return sp.run(c, shell=True, capture_output=True, text=True, check=False)

          # Find conflicted files (stages 1/2/3 present)
          out = sh("git ls-files -u | cut -f2 | sort -u")
          files = [f for f in out.stdout.splitlines() if f]

          CON = re.compile(r"<<<<<<< [^\n]+\n(.*?)\n=======\n(.*?)\n>>>>>>> [^\n]+\n", re.S)

          # Build per-file markdown with OURS/THEIRS blocks
          payloads = []
          MAX = 28000  # keep well under GH comment body limit (~65k). We'll split big files.
          for path in files:
              p = pathlib.Path(path)
              try:
                  t = p.read_text(errors="ignore")
              except Exception:
                  continue
              blocks = []
              for i,m in enumerate(CON.finditer(t), start=1):
                  ours = m.group(1).rstrip()
                  theirs = m.group(2).rstrip()
                  chunk = f"**{path} â€” conflict {i}**\n\n" \
                          f"```diff\n<<<<<<< OURS\n{ours}\n=======\n{theirs}\n>>>>>>> THEIRS\n```\n"
                  blocks.append(chunk)
              if not blocks:
                  continue
              body = f"@{os.environ.get('CODEX_HANDLE','codex').lstrip('@')} please resolve the conflicts in `{path}`.\n" \
                     f"Return **GitHub Suggested changes** if possible; otherwise reply with a full file replacement in a fenced block like:\n\n" \
                     f"```resolved:{path}\n<entire corrected file contents>\n```\n\n" \
                     + "\n".join(blocks)

              # split large comments
              if len(body) <= MAX:
                  payloads.append(body)
              else:
                  parts = math.ceil(len(body)/MAX)
                  for i in range(parts):
                      payloads.append(f"(part {i+1}/{parts})\n\n" + body[i*MAX:(i+1)*MAX])

          # Post each payload as an issue comment with the PR number from environment
          if payloads:
              # use gh api (already installed on hosted runners)
              for body in payloads:
                  body = body.replace('"','\\"').replace("$","\\$")  # escape shell
                  cmd = f'gh api repos/${{GITHUB_REPOSITORY}}/issues/${{steps.pr.outputs.number}}/comments -f body="{body}"'
                  sh(cmd)
          PY
        env:
          GH_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          CODEX_HANDLE: ${{ env.CODEX_HANDLE }}